{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual image search\n",
    "_**Using a Convolutional Neural Net and Elasticsearch k-Nearest Neighbors Index to retrieve visually similar images**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [GluonCV(MXNet) Model Preparation](#GluonCV(MXNet)-Model-Preparation)\n",
    "1. [SageMaker Model Hosting (BYOC)](#Hosting-Model-BYOC)\n",
    "1. [Build a KNN Index in Elasticsearch](#ES-KNN)\n",
    "1. [Evaluate Index Search Results](#Searching-with-ES-k-NN)\n",
    "1. [Extensions](#Extensions)\n",
    "\n",
    "## Background\n",
    "在这个笔记本中，我们将建立一个视觉图像搜索应用程序的核心组件。视觉图像搜索用于界面中，在这里，你不是通过语音或文字来询问什么，而是展示你要找的东西的照片例子。\n",
    "\n",
    "视觉图像搜索的核心组件之一是一个卷积神经网络（CNN）模型，它生成代表查询图像和参考项目图像的 \"特征向量\"，以便与查询进行比较。参考项目的特征向量通常是离线生成的，并且必须存储在某种数据库中，以便能够有效地进行搜索。对于小的参考项目数据集，可以使用蛮力搜索，将查询与每个参考项目进行比较。然而，这对于大型数据集来说是不可行的，因为蛮力搜索会变得非常慢。\n",
    "\n",
    "为了能够有效地搜索视觉上相似的图像，我们将使用Amazon SageMaker从图像中生成 \"特征向量\"，并在Amazon Elasticsearch服务中使用KNN算法。亚马逊Elasticsearch服务的KNN让你在向量空间中搜索点，并通过欧氏距离或余弦相似度（默认为欧氏距离）为这些点找到 \"最近的邻居\"。用例包括推荐（例如，在音乐应用程序中的 \"你可能喜欢的其他歌曲 \"功能）、图像识别和欺诈检测。\n",
    "\n",
    "以下是我们建立视觉图像搜索的步骤。在一些初始设置之后，我们将使用TensorFlow准备一个模型来生成特征向量，然后从feidegger（一个zalandoresearch数据集）生成时尚图片的特征向量。这些特征向量将被导入Amazon Elasticsearch KNN Index。接下来，我们将探索一些测试图像查询，并将结果可视化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install tqdm to have progress bar\n",
    "!pip install tqdm -i https://opentuna.cn/pypi/web/simple\n",
    "\n",
    "#install necessary pkg to make connection with elasticsearch domain\n",
    "!pip install elasticsearch==7.13.0 -i https://opentuna.cn/pypi/web/simple\n",
    "!pip install requests -i https://opentuna.cn/pypi/web/simple\n",
    "!pip install requests-aws4auth -i https://opentuna.cn/pypi/web/simple\n",
    "\n",
    "!pip install gluoncv -i https://opentuna.cn/pypi/web/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "def get_cfn_outputs(stackname):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "## Setup variables to use for the rest of the demo\n",
    "cloudformation_stack_name = \"vis-search\"\n",
    "\n",
    "outputs = get_cfn_outputs(cloudformation_stack_name)\n",
    "\n",
    "bucket = outputs['s3BucketTraining']\n",
    "es_host = outputs['esHostName']\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.path.abspath('.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/ec2-user/SageMaker/sagemaker-visual-image-search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://sagemaker-cn-northwest-1-456370280007.s3.cn-northwest-1.amazonaws.com.cn/visual-search/datas.pkl\n",
    "!wget https://sagemaker-cn-northwest-1-456370280007.s3.cn-northwest-1.amazonaws.com.cn/visual-search/datas.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 从pkl提取图片\n",
    "\n",
    "import joblib\n",
    "\n",
    "datas = joblib.load(open('datas.pkl', 'rb'))\n",
    "\n",
    "print(type(datas))\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(datas.shape[0])):\n",
    "#     im = Image.fromarray(datas[i]*255)\n",
    "#     im = im.convert('L')\n",
    "#     im.save('images/'+str(i)+'.png')\n",
    "    plt.imshow(datas[i])\n",
    "    plt.axis('off')\n",
    "    plt.savefig('images/'+str(i)+'.png')\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -o -d ./images datas.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive images/ s3://$bucket/images/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GluonCV(MXNet) Model Preparation\n",
    "\n",
    "我们将使用MXNet后端来准备一个模型，将图像 \"featurizing \"为特征向量。MXNet有一个本地模块API，以及一个更高级别的Gluon API。\n",
    "\n",
    "我们将从一个预训练的模型开始，避免花时间和从头训练一个模型。因此，作为准备模型的第一步，我们将从GluonCV应用程序中导入一个预训练的模型。研究人员已经试验了各种不同层数的预训练CNN架构，发现有几种很好的可能性。\n",
    "\n",
    "在这个笔记本中，我们将选择一个基于ResNet架构的模型，这是一个常用的选择。在层数的各种选择中，从18到152不等，我们将使用50层。这也是一个常见的选择，它平衡了所产生的特征向量（嵌入）的表现力和计算效率（较少的层数意味着更高的效率，但代价是较少的表现力）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O endpoint/model.zip \"https://datalab.s3.amazonaws.com/data/model.zip?AWSAccessKeyId=AKIAYNUCDPLSDWHHQJ7Y&Signature=n1mr3WUiLSXIrnK64%2FnvFhf8sC8%3D&Expires=1648453473\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd endpoint && unzip -o -q model.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import gluon, image, init, nd\n",
    "from gluoncv.model_zoo import get_model\n",
    "from gluoncv.data.transforms.presets.imagenet import transform_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 0\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)] if num_gpus > 0 else [mx.cpu()]\n",
    "\n",
    "model_name = 'ResNet50_v2'\n",
    "classes = 5\n",
    "\n",
    "finetune_net = get_model(model_name, pretrained=True)\n",
    "with finetune_net.name_scope():\n",
    "    finetune_net.output = nn.Dense(classes)\n",
    "finetune_net.output.initialize(init.Xavier(), ctx = ctx)\n",
    "finetune_net.collect_params().reset_ctx(ctx)\n",
    "finetune_net.hybridize()\n",
    "\n",
    "finetune_net.load_parameters('endpoint/model/model-0000.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pic = './images/100.png'\n",
    "\n",
    "# Load Images\n",
    "img = image.imread(input_pic)\n",
    "\n",
    "# Transform\n",
    "img = transform_eval(img).copyto(ctx[0])\n",
    "    \n",
    "finetune_net(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Model Hosting (BYOC)\n",
    "```\n",
    "cd endpoint\n",
    "./build_and_push.sh image-embedding\n",
    "python create_endpoint.py\n",
    "docker run -v -d -p 8080:8080 image-embedding\n",
    "python test.py\n",
    "python test-x-image.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.path.abspath('.'))\n",
    "\n",
    "%cd /home/ec2-user/SageMaker/sagemaker-visual-image-search/endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh ./build_and_push.sh image-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_endpoint_running(endpoint_name):\n",
    "    \"\"\"\n",
    "    Content of check_name could be \"InService\" or other.\n",
    "    if the named endpoint doesn't exist then return None.\n",
    "    \"\"\"\n",
    "    client = boto3.client('sagemaker')\n",
    "    endpoints = client.list_endpoints()\n",
    "    endpoint_name_list = [(ep[\"EndpointName\"], ep[\"EndpointStatus\"]) for ep in endpoints[\"Endpoints\"]]\n",
    "    for check_name in endpoint_name_list:\n",
    "        if endpoint_name == check_name[0]:\n",
    "            return check_name[1]\n",
    "    return None\n",
    "\n",
    "def deploy_endpoint():\n",
    "    \n",
    "    if is_endpoint_running(endpoint_name) is not None:\n",
    "        print(\"Endpoint already exist and will return.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        sm = boto3.Session().client('sagemaker')\n",
    "        primary_container = {'Image': endpoint_ecr_image_path}\n",
    "        print(\"model_name: \", endpoint_name)\n",
    "        print(\"endpoint_ecr_image_path: \", endpoint_ecr_image_path)\n",
    "        \n",
    "        try:\n",
    "            create_model_response = sm.create_model(ModelName=endpoint_name,\n",
    "                                                    ExecutionRoleArn=role,\n",
    "                                                    PrimaryContainer=primary_container)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # create endpoint config\n",
    "        endpoint_config_name = endpoint_name + '-config'\n",
    "        try:\n",
    "            create_endpoint_config_response = sm.create_endpoint_config(EndpointConfigName=endpoint_config_name,\n",
    "                                                                        ProductionVariants=[{\n",
    "                                                                            'InstanceType': instance_type,\n",
    "                                                                            'InitialVariantWeight': 1,\n",
    "                                                                            'InitialInstanceCount': 1,\n",
    "                                                                            'ModelName': endpoint_name,\n",
    "                                                                            'VariantName': 'AllTraffic'}])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # create endpoint\n",
    "        create_endpoint_response = sm.create_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"!!! Cannot create endpoint - Exception is >> {}\".format(e))\n",
    "        if type(e).__name__ == \"StateMachineAlreadyExists\":\n",
    "            print(\"Skip sf creation because it is created before.\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    print(\"<<< Completed model endpoint deployment. \" + str(endpoint_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = !aws sts get-caller-identity --query Account --output text\n",
    "endpoint_name = \"image-embedding\"\n",
    "endpoint_ecr_image_path = account[0] + \".dkr.ecr.cn-northwest-1.amazonaws.com.cn/image-embedding\"\n",
    "instance_type = \"ml.m5.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a KNN Index in Elasticsearch\n",
    "\n",
    "KNN for Amazon Elasticsearch Service lets you search for points in a vector space and find the \"nearest neighbors\" for those points by Euclidean distance or cosine similarity (default is Euclidean distance). Use cases include recommendations (for example, an \"other songs you might like\" feature in a music application), image recognition, and fraud detection.\n",
    "\n",
    "KNN requires Elasticsearch 7.1 or later. Full documentation for the Elasticsearch feature, including descriptions of settings and statistics, is available in the Open Distro for Elasticsearch documentation. For background information about the k-nearest neighbors algorithm\n",
    "\n",
    "In this step we'll get all the features zalando images and import those features into Elastichseach7.4 domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define some utility function\n",
    "\n",
    "#return all s3 keys\n",
    "def get_all_s3_keys(bucket):\n",
    "    \"\"\"Get a list of all keys in an S3 bucket.\"\"\"    \n",
    "    keys = []\n",
    "\n",
    "    kwargs = {'Bucket': bucket}\n",
    "    while True:\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        for obj in resp['Contents']:\n",
    "            if obj['Key'].endswith('.png'):\n",
    "                keys.append('s3://' + bucket + '/' + obj['Key'])\n",
    "\n",
    "        try:\n",
    "            kwargs['ContinuationToken'] = resp['NextContinuationToken']\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the zalando images keys from the bucket make a list\n",
    "s3_uris = get_all_s3_keys(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s3_uris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_uris[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract image features\n",
    "from time import sleep\n",
    "import json\n",
    "\n",
    "sm_client = boto3.client('sagemaker-runtime')\n",
    "ENDPOINT_NAME = 'image-embedding'  # predictor.endpoint\n",
    "\n",
    "def get_predictions(payload):\n",
    "    return sm_client.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n",
    "                                           ContentType='application/json',  # 'application/x-image'\n",
    "                                           Body=payload)\n",
    "\n",
    "def extract_features(s3_uri):\n",
    "    key = s3_uri.replace(f's3://{bucket}/', '')\n",
    "    payload = json.dumps({'bucket' : bucket, 'image_uri' : key, 'content_type': \"application/json\"})  # s3.get_object(Bucket=bucket,Key=key)['Body'].read()\n",
    "    try:\n",
    "        response = get_predictions(payload)\n",
    "    except:\n",
    "        sleep(0.1)\n",
    "        response = get_predictions(payload)\n",
    "\n",
    "    del payload\n",
    "    response_body = json.loads((response['Body'].read()))\n",
    "    feature_lst = response_body  # response_body['predictions'][0]\n",
    "    \n",
    "    return s3_uri, feature_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resulti = extract_features(s3_uris[0])\n",
    "print(resulti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_uris[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# This process cell will take approximately 24-25 minutes on a t3.medium notebook instance\n",
    "# with 3 m5.xlarge SageMaker Hosted Endpoint instances\n",
    "from multiprocessing import cpu_count\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "workers = 4  # TODO if your endpoint instance is large enough: 2 * cpu_count()\n",
    "result = process_map(extract_features, s3_uris, max_workers=workers, chunksize=4)  # TODO use 100 images for sample, s3_uris[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the Elasticsearch connection\n",
    "from elasticsearch import Elasticsearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "region = 'cn-northwest-1' # e.g. us-east-1/cn-northwest-1\n",
    "service = 'es'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
    "\n",
    "es = Elasticsearch(\n",
    "    hosts = [{'host': es_host, 'port': 443}],\n",
    "    http_auth = awsauth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define KNN Elasticsearch index maping\n",
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"geo_img_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 2048\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Elasticsearch index\n",
    "#es.indices.delete(index=\"idx_geo\")\n",
    "es.indices.create(index=\"idx_geo\",body=knn_index,ignore=400)\n",
    "es.indices.get(index=\"idx_geo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# defining a function to import the feature vectors corrosponds to each S3 URI into Elasticsearch KNN index\n",
    "# This process will take around ~3 min.\n",
    "\n",
    "\n",
    "def es_import(i):\n",
    "    es.index(index='idx_geo',\n",
    "             body={\"geo_img_vector\": i[1]['predictions'][0], \n",
    "                   \"image\": i[0]}\n",
    "            )\n",
    "    \n",
    "_ = process_map(es_import, result, max_workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Index Search Results\n",
    "\n",
    "In this step we will use SageMaker SDK as well as Boto3 SDK to query the Elasticsearch to retrive the nearest neighbours. One thing to mention **geo** dataset has pretty good similarity with Imagenet dataset. Now if you hav a very domain speific problem then then you need to train that dataset on top of pretrained feature extractor model such as VGG, Resnet, Xeception, Mobilenet etc and bulid a new feature extractor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define display_image function\n",
    "def display_image(bucket, key):\n",
    "    response = s3.get_object(Bucket=bucket,Key=key)['Body']\n",
    "    img = Image.open(response)\n",
    "    return display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "from PIL import Image\n",
    "import io\n",
    "# urls = []\n",
    "# # yellow pattern dess\n",
    "# urls.append('https://fastly.hautelookcdn.com/products/D7242MNR/large/13494318.jpg')\n",
    "# # T shirt kind dress\n",
    "# urls.append('https://fastly.hautelookcdn.com/products/M2241/large/15658772.jpg')\n",
    "# #Dotted pattern dress\n",
    "# urls.append('https://fastly.hautelookcdn.com/products/19463M/large/14537545.jpg')\n",
    "\n",
    "# img_bytes = requests.get(random.choice(urls)).content\n",
    "# query_img = Image.open(io.BytesIO(img_bytes))\n",
    "# query_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SageMaker SDK Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#SageMaker SDK approach\n",
    "predictor.content_type = 'application/x-image'\n",
    "predictor.serializer   = None\n",
    "features = predictor.predict(img_bytes)['predictions'][0]\n",
    "'''\n",
    "# Boto3 approach\n",
    "tmp_bucket = bucket\n",
    "s3_uri = f's3://{bucket}/images/3100.png'\n",
    "key = s3_uri.replace(f's3://{tmp_bucket}/', '')\n",
    "payload = json.dumps({'bucket' : tmp_bucket, 'image_uri' : key, 'content_type': \"application/json\"})  # s3.get_object(Bucket=bucket,Key=key)['Body'].read()\n",
    "response = get_predictions(payload)\n",
    "response_body = json.loads((response['Body'].read()))\n",
    "features = response_body['predictions'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "k = 5\n",
    "idx_name = 'idx_geo'\n",
    "res = es.search(request_timeout=30, index=idx_name,\n",
    "                body={'size': k, \n",
    "                      'query': {'knn': {'geo_img_vector': {'vector': features, 'k': k}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "    key = res['hits']['hits'][i]['_source']['image'] \n",
    "    key = key.replace(f's3://{bucket}/','')\n",
    "    if key.startswith('s3'):\n",
    "        key = 'images'+key\n",
    "    print(key)\n",
    "    img = display_image(bucket,key)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a full-stack visual search application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_template_url = f'https://sagemaker-cn-northwest-1-456370280007.s3.cn-northwest-1.amazonaws.com.cn/visual-search/template-cn.yaml'\n",
    "\n",
    "\n",
    "\n",
    "# 生成CloudFormation快速创建链接，复制到浏览器中开启CloudFormation向导，等待执行完毕\n",
    "\n",
    "print(\"Click the URL below to create the backend API for visual search:\\n\")\n",
    "print((\n",
    "    'https://cn-northwest-1.console.amazonaws.cn/cloudformation/home?region=cn-northwest-1#/stacks/create/review'\n",
    "    f'?templateURL={sam_template_url}'\n",
    "    '&stackName=vis-search-api'\n",
    "    f'&param_BucketName={outputs[\"s3BucketTraining\"]}'\n",
    "    f'&param_DomainName={outputs[\"esDomainName\"]}'\n",
    "    f'&param_ElasticSearchURL={outputs[\"esHostName\"]}'\n",
    "    f'&param_SagemakerEndpoint=image-embedding'  # TODO predictor.endpoint\n",
    "))\n",
    "\n",
    "BucketName = f\"s3://{outputs['s3BucketTraining']}\"\n",
    "DomainName = f\"s3://{outputs['esDomainName']}\"\n",
    "ElasticSearchURL = f\"s3://{outputs['esHostName']}\"\n",
    "SagemakerEndpoint = \"image-embedding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a working Amazon SageMaker endpoint for extracting image features and a KNN index on Elasticsearch, you are ready to build a real-world full-stack ML-powered web app. The SAM template you just created will deploy an Amazon API Gateway and AWS Lambda function. The Lambda function runs your code in response to HTTP requests that are sent to the API Gateway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the content of the Lambda function code.\n",
    "#!pygmentize backend/lambda/app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once the CloudFormation Stack shows CREATE_COMPLETE, proceed to this cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/ec2-user/SageMaker/sagemaker-visual-image-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the REST endpoint for the search API to a config file, to be used by the frontend build\n",
    "\n",
    "import json\n",
    "api_endpoint = get_cfn_outputs('vis-search-api')['ImageSimilarityApi']\n",
    "print(api_endpoint)\n",
    "#api_endpoint = 'https://s42995b1j7.execute-api.cn-northwest-1.amazonaws.com.cn/Prod'\n",
    "\n",
    "with open('./frontend/src/config/config.json', 'w') as outfile:\n",
    "    json.dump({'apiEndpoint': api_endpoint}, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Deploy frontend services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add NPM to the path so we can assemble the web frontend from our notebook code\n",
    "\n",
    "from os import environ\n",
    "\n",
    "npm_path = ':/home/ec2-user/anaconda3/envs/JupyterSystemEnv/bin'\n",
    "\n",
    "if npm_path not in environ['PATH']:\n",
    "    ADD_NPM_PATH = environ['PATH']\n",
    "    ADD_NPM_PATH = ADD_NPM_PATH + npm_path\n",
    "else:\n",
    "    ADD_NPM_PATH = environ['PATH']\n",
    "    \n",
    "%set_env PATH=$ADD_NPM_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./frontend/\n",
    "\n",
    "!npm install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!npm run-script build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosting_bucket = f\"s3://{outputs['s3BucketHostingBucketName']}\"\n",
    "\n",
    "!aws s3 sync ./build/ $hosting_bucket --acl public-read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Browse your frontend service, and upload an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Click the URL below:\\n')\n",
    "print(outputs['WebsiteURL'] + '/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the following page:\n",
    "\n",
    "![Website](pi3small.png)\n",
    "\n",
    "On the website, try pasting the following URL in the URL text field.\n",
    "\n",
    "`https://i4.ztat.net/large/VE/12/1C/14/8K/12/VE121C148-K12@10.jpg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "We have used pretrained Resnet50 model which is trained on Imagenet dataset. Now based on your use-case you can fine tune any pre-trained models, such as VGG, Inception, and MobileNet with your own dataset and host the model in Amazon SageMaker.\n",
    "\n",
    "You can also use Amazon SageMaker Batch transform job to have a bulk feaures extracted from your stored S3 images and then you can use AWS Glue to import that data into Elasticeearch domain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "Make sure that you stop the notebook instance, delete the Amazon SageMaker endpoint and delete the Elasticsearch domain to prevent any additional charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the endpoint\n",
    "# predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty S3 Contents\n",
    "# training_bucket_resource = s3_resource.Bucket(bucket)\n",
    "# training_bucket_resource.objects.all().delete()\n",
    "\n",
    "# hosting_bucket_resource = s3_resource.Bucket(outputs['s3BucketHostingBucketName'])\n",
    "# hosting_bucket_resource.objects.all().delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
